{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAP HANA Cloud - Auto ML Hands On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "- SAP HANA Python Client API for Machine Learning Algorithms: https://pypi.org/project/hana-ml/\n",
    "\n",
    "- SAP HANA Predictive Analysis Library (PAL): https://help.sap.com/viewer/2cfbc5cf2bc14f028cfbe2a2bba60a50/1.0.12/en-US\n",
    "\n",
    "SAP HANA ML Library\n",
    "You will be using the 'SAP HANA Python Client API for Machine Learning Algorithm'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade hana_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hana_ml\n",
    "print(hana_ml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hana_address = #your hostname as string\n",
    "hana_port = #your port as integer\n",
    "hana_user = #your user as string\n",
    "hana_password = #your password as string\n",
    "hana_encrypt = True #for HANA Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hana_ml.dataframe as dataframe\n",
    "\n",
    "# Establish connection\n",
    "conn = dataframe.ConnectionContext(address = hana_address,\n",
    "                                   port = hana_port, \n",
    "                                   user = hana_user, \n",
    "                                   password = hana_password, \n",
    "                                   encrypt = hana_encrypt,\n",
    "                                   sslValidateCertificate = 'false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through a HANA Key we are able to hide our login credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hana_ml.dataframe as dataframe\n",
    "\n",
    "# Establish connection\n",
    "conn = dataframe.ConnectionContext(userkey = 'MYHANACLOUD',\n",
    "                                   encrypt = 'true',\n",
    "                                   sslValidateCertificate = 'false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#load data, change path to your directory\n",
    "df = pd.read_csv(r\"YourPath\\BB_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change columns to upper string\n",
    "df.columns = map(str.upper, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert a product ID, which will later be used as key\n",
    "df.insert(0, 'TRANSACTION_ID', df.reset_index().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control a sample of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Create a SAP HANA dataframe and point it to the table with the uploaded data.\n",
    "df_remote = dataframe.create_dataframe_from_pandas(connection_context = conn, \n",
    "                                                   pandas_df = df, \n",
    "                                                   table_name = 'TRANSACTIONS',\n",
    "                                                   force = True,\n",
    "                                                   replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remote = conn.table(\"TRANSACTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control the size of the data\n",
    "df_remote.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control the variable types in SAP HANA\n",
    "df_remote.dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the variable QUALITY\n",
    "df_remote = df_remote.cast('FRAUD', 'NVARCHAR(20)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remote = df_remote.cast('AMOUNT', 'DOUBLE')\n",
    "df_remote = df_remote.cast('OLD_BALANCE_ORIGIN', 'DOUBLE')\n",
    "df_remote = df_remote.cast('NEW_BALANCE_ORIGIN', 'DOUBLE')\n",
    "df_remote = df_remote.cast('OLD_BALANCE_DEST', 'DOUBLE')\n",
    "df_remote = df_remote.cast('NEW_BALANCE_DEST', 'DOUBLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#control the variable types\n",
    "df_remote.dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#describe the data in SAP HANA\n",
    "df_remote.describe().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#create training and testing set\n",
    "from hana_ml.algorithms.pal import partition\n",
    "df_remote_train, df_remote_test, df_remote_val = partition.train_test_val_split(data = df_remote, \n",
    "                                                                                   training_percentage = 0.5, \n",
    "                                                                                   testing_percentage = 0.5,\n",
    "                                                                                   validation_percentage = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control the size of the training and testing set\n",
    "print('Size of training subset: ' + str(df_remote_train.count()))\n",
    "print('Size of test subset: ' + str(df_remote_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml import dataframe\n",
    "from hana_ml.dataframe import ConnectionContext\n",
    "from hana_ml.algorithms.pal.utility import DataSets, Settings\n",
    "from hana_ml.algorithms.pal.partition import train_test_val_split\n",
    "from hana_ml.algorithms.pal.auto_ml import AutomaticClassification, AutomaticRegression\n",
    "from hana_ml.visualizers.automl_progress import PipelineProgressStatusMonitor\n",
    "from hana_ml.visualizers.automl_report import BestPipelineReport\n",
    "from hana_ml.visualizers.unified_report import UnifiedReport\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute_sql('''\n",
    "CREATE WORKLOAD CLASS \"PAL_AUTOML_WORKLOAD\" SET 'PRIORITY' = '3', 'STATEMENT MEMORY LIMIT' = '3' , 'STATEMENT THREAD LIMIT' = '20'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "scenario_id = \"{}_AutoMLc_{}\".format(\"<YourName>\", uuid.uuid1())\n",
    "print(scenario_id)\n",
    "\n",
    "# Set the initial AutoML scenario parameters\n",
    "auto_c = AutomaticClassification(generations=2, \n",
    "                                 population_size=5,\n",
    "                                 offspring_size=5, \n",
    "                                 elite_number=5,\n",
    "                                 random_seed=1234,\n",
    "                                 progress_indicator_id=scenario_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize the AutoML operators and their parameters\n",
    "auto_c.reset_config_dict(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_c.display_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the AutoML Classification Scenario\n",
    "\n",
    "# Drop all Resampler\n",
    "auto_c.delete_config_dict(\"SAMPLING\")\n",
    "auto_c.delete_config_dict(\"SMOTE\")\n",
    "auto_c.delete_config_dict(\"TomekLinks\")\n",
    "\n",
    "auto_c.display_config_dict(category=\"Resampler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop and select Transformer\n",
    "auto_c.delete_config_dict(category=\"Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop and select  Classifier\n",
    "auto_c.delete_config_dict(\"DT_Classifier\")\n",
    "auto_c.delete_config_dict(\"SVM_Classifier\")\n",
    "auto_c.delete_config_dict(\"NB_Classifier\")\n",
    "auto_c.delete_config_dict(\"MLP_Classifier\")\n",
    "auto_c.delete_config_dict(\"RDT_Classifier\")\n",
    "\n",
    "auto_c.display_config_dict(category=\"Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change / update Classifier parameter values and ranges\n",
    "auto_c.update_config_dict(\"M_LOGR_Classifier\", \"ENET_LAMBDA\", [0.001, 0.01, 0.1])\n",
    "auto_c.display_config_dict(\"M_LOGR_Classifier\")\n",
    "\n",
    "auto_c.update_config_dict(\"HGBT_Classifier\", \"ETA\", [1e-2, 1e-1, 0.5])\n",
    "auto_c.update_config_dict(\"HGBT_Classifier\", \"MAX_DEPTH\", {'range': [1, 1, 11]})\n",
    "auto_c.update_config_dict(\"HGBT_Classifier\", \"NODE_SIZE\", {'range': [1, 1, 21]})\n",
    "auto_c.display_config_dict(\"HGBT_Classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review complete AutoML Classification configuration\n",
    "auto_c.display_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# enable_workload_class\n",
    "auto_c.enable_workload_class(workload_class_name=\"PAL_AUTOML_WORKLOAD\")\n",
    "\n",
    "# invoke a PipelineProgressStatusMonitor\n",
    "progress_status_monitor = PipelineProgressStatusMonitor(connection_context= conn, \n",
    "                                                        automatic_obj=auto_c)\n",
    "\n",
    "progress_status_monitor.start()\n",
    "\n",
    "# training\n",
    "try:\n",
    "    auto_c.fit(data=df_remote_train, key='TRANSACTION_ID', label = \"FRAUD\")\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = auto_c.model_[1].collect().iat[0, 1]\n",
    "res_ev = auto_c.evaluate(df_remote_test, pipeline=pipeline)\n",
    "print(res_ev.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = auto_c.predict(df_remote_test.deselect(\"FRAUD\"), key = 'TRANSACTION_ID')\n",
    "print(res.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.model_storage import ModelStorage\n",
    "MODEL_SCHEMA = 'YourSchema' # HANA schema in which models are to be saved\n",
    "model_storage = ModelStorage(connection_context=conn, schema=MODEL_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_c.name = 'AutoML Classification' \n",
    "auto_c.version = 1\n",
    "model_storage.save_model(model=auto_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
