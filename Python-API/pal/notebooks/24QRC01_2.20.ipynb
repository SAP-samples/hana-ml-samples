{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d88e7e-f3f6-4191-9950-4bbedef19861",
   "metadata": {},
   "source": [
    "# Python Machine Learning client for SAP HANA, release 2.20 enhancements sample notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55273c5-7199-410e-9de0-c1b6b53dfe43",
   "metadata": {},
   "source": [
    "The changelog of enhancements with the release version 2.20.240319 can be found [in the documentation](https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2024_1_QRC/en-US/change_log.html), and are summaried below  <br><br>\n",
    "__New functions__<br>\n",
    "    - Added Bubble Plot function: `hana_ml.visualizers.eda.buble_plot` and Parallel Co-ordinate Plot function: `hana_ml.visualizers.eda.parallel_coordinates` in EDA. <br>\n",
    "    - Added time series permutation feature importance function:`hana_ml.algorithms.pal.tsa.permutation_importance`.<br>\n",
    "    - Added MLP Recommender class: `hana_ml.algorithms.pal.recommender.MLPRecommender`.<br>\n",
    "<br>\n",
    "__Enhancements__<br>\n",
    "    - Enhanced progress monitor for AutoML to display at anytime. Especially for the scheduled job.<br>\n",
    "    - Support algorithm-specific parameters in automl/pipeline predict. Effect in both pipline and automl module.<br>\n",
    "    - Enhanced AutoML Auto SQL Content Integration for progress log management.<br>\n",
    "    - Enhanced pipeline report to display connection scores.<br>\n",
    "    - Enhanced AutoML config_dict templates with new operators.<br>\n",
    "    - Enhanced AutoML with connection constraints option.<br>\n",
    "    - Enhanced AUtoML with different logging levels.<br>\n",
    "    - Enhanced AutoML with random/grid search option.<br>\n",
    "    - Enhanced outlier_detection with voting logic.<br>\n",
    "    - Enhanced online BCPD in massive mode.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b07eb-11ef-41d6-a9db-2c0ffe1e536f",
   "metadata": {},
   "source": [
    "## Connect to your SAP HANA Cloud instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f411a-9d0f-4987-a1d8-b65e686b100f",
   "metadata": {},
   "source": [
    "The latest Python ML client for SAP HANA package update ready for installation can be found at: https://pypi.org/project/hana-ml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98fc5e-2925-45ea-8bcc-7adc83cb5899",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the Python Machine Learning client library for SAP HANA and get the version\n",
    "import hana_ml\n",
    "print(hana_ml.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3adcc-0b17-4923-b9f3-f22c1591a536",
   "metadata": {},
   "source": [
    "Connect using the secure user connection store (hdbuserstore) and a connection key, see  [documentation](https://help.sap.com/docs/SAP_HANA_CLIENT/f1b440ded6144a54ada97ff95dac7adf/708e5fe0e44a4764a1b6b5ea549b88f4.html).  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "82d04eae-0c7a-42ba-b69b-9829f9e55e56",
   "metadata": {},
   "source": [
    "# CMD Prompt:\n",
    "# cd <install-dir>\\SAP\\hdbclient>\n",
    "# hdbuserstore -i set <your-key-name> \"<hana-cloud-hostname>:443\" <HANA username> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a24997-efd3-4f8d-b333-f9681c008bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SAP HANA CLoud connection\n",
    "import hana_ml.dataframe as dataframe\n",
    "#cc = dataframe.ConnectionContext( address=\"<hana-cloud-hostname>\", port=443,  user=\"<HANA-user>\")\n",
    "#cc = dataframe.ConnectionContext( userkey=<your-key-name>, sslValidateCertificate=False)\n",
    "\n",
    "# Utilize connection credentials from external file\n",
    "from hana_ml.dataframe import ConnectionContext\n",
    "from hana_ml.algorithms.pal.utility import Settings\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\", \"api\")\n",
    "cc = ConnectionContext(url, port, user, pwd)\n",
    "\n",
    "# Control connection\n",
    "print(cc.connection.isconnected())\n",
    "print(cc.hana_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f61093-992e-45e6-80eb-42c40b34f580",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AutoML enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef589f03-ad85-45a0-b4c1-f2fa9acdd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load sample datasets for the AutoML example\n",
    "from hana_ml.algorithms.pal.utility import DataSets\n",
    "\n",
    "#load titanic data to HANA\n",
    "full, train, test, validate = DataSets.load_titanic_data(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815f9ea-58a2-410f-a6eb-1e75e35474c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the descriptive statistics overviewing the titanic SAP HANA training dataframe\n",
    "train.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a1cd6-eb9b-479f-9c7e-9097e7b8c7ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AutoML fit and best pipeline report with connection constraints option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e21c88-5a85-4cb2-99c5-be19ac61e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using AutoML with Connectivity optimization\n",
    "import uuid\n",
    "from hana_ml.algorithms.pal.auto_ml import AutomaticClassification\n",
    "\n",
    "progress_id = \"automl_{}\".format(uuid.uuid1())\n",
    "auto_c = AutomaticClassification(generations=5, \n",
    "                                 population_size=10,\n",
    "                                 offspring_size=10,\n",
    "                                 config_dict='light',\n",
    "                                 connections='default',\n",
    "                                 scorings={'AUC': 0.5, 'ACCURACY': 0.5},\n",
    "                                 progress_indicator_id=progress_id)\n",
    "\n",
    "auto_c.disable_workload_class_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4334a-5273-477f-93bf-4565d5247277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the AutoML classification model\n",
    "from hana_ml.visualizers.automl_progress import PipelineProgressStatusMonitor\n",
    "\n",
    "progress_status_monitor = PipelineProgressStatusMonitor(connection_context=cc, \n",
    "                                                        automatic_obj=auto_c)\n",
    "progress_status_monitor.start()\n",
    "\n",
    "auto_c.fit(data=train.cast({\"SURVIVED\": \"VARCHAR(10)\"}), \n",
    "           key=\"PASSENGER_ID\", \n",
    "           label=\"SURVIVED\")\n",
    "\n",
    "auto_c.runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c8309-7c9e-4d9c-ab39-136ecb65c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show enhanced best pipeline report with the new connection-tab in the report\n",
    "from hana_ml.visualizers.unified_report import UnifiedReport\n",
    "\n",
    "UnifiedReport(auto_c).build().display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba18395-2758-4e96-84ce-8c442f673a97",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Search Option in AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de18f1-92da-4e82-8d98-06a2aaa851d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a time series data set, for illustrations of the new Random Search option with AutoML\n",
    "import pandas as pd\n",
    "from hana_ml.algorithms.pal.auto_ml import AutomaticTimeSeries\n",
    "from hana_ml.dataframe import create_dataframe_from_pandas\n",
    "\n",
    "data = [0,3.530127019,-5.930127019,-2.4,1.130127019,-8.330127019,-4.8,-1.269872981,-10.73012702,-7.2,-3.669872981,-13.13012702,-9.6,-6.069872981,-15.53012702,-12,-8.469872981,-17.93012702,-14.4,-10.86987298,-20.33012702,-16.8,-13.26987298,-22.73012702,-19.2,-15.66987298,-25.13012702,-25.13012702,-20.37484444,-22.19120076,-28.06905328,-29.8854096,-25.13012702,-20.37484444,-22.19120076,-28.06905328,-29.8854096,-25.13012702,-20.37484444,-22.19120076,-28.06905328,-29.8854096,-25.13012702,-20.37484444,-22.19120076,-28.06905328,-29.8854096,-25.13012702,-20.37484444,-22.19120076,-28.06905328,-29.8854096,5,8.909157412,9.874639561,7.169418696,2.830581304,0.125360439,1.090842588,5,8.909157412,9.874639561,7.169418696,2.830581304,0.125360439,1.090842588,5,8.909157412,9.874639561,7.169418696,2.830581304,0.125360439,1.090842588,5,8.909157412,9.874639561,7.169418696,2.830581304,0.125360439,1.090842588,5,8.909157412,9.874639561,7.169418696,2.830581304,0.125360439,1.090842588]\n",
    "df = pd.DataFrame({'ID':[i for i in range(len(data))],'SERIES':data})   \n",
    "dt_ml = create_dataframe_from_pandas(cc, df, table_name='#PAL_DATA_TBL', force=True)\n",
    "\n",
    "#ts = cc.table('PAL_DATA_TBL')\n",
    "print(len(dt_ml.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec3859-9c4c-40a9-ae11-e3ebb1a92aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a AutoML time series analysis scenario and use RANDOM search optimization instead of the Genetic Algorithm optimization\n",
    "progress_id = \"automl_ts_{}\".format(uuid.uuid1())\n",
    "\n",
    "auto_ts = AutomaticTimeSeries(progress_indicator_id=progress_id,\n",
    "                              config_dict=\"default\",\n",
    "                              search_method='random')\n",
    "\n",
    "auto_ts.disable_workload_class_check()\n",
    "\n",
    "auto_ts.fit(data=dt_ml, key='ID', endog=\"SERIES\")  \n",
    "auto_ts.runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f465b-0b90-4f5a-ab42-87ad2e52a0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_predict = auto_ts.make_future_dataframe(periods=10)\n",
    "res = auto_ts.predict(df_predict, key=\"ID\")\n",
    "print(res.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b02e9b-d336-40a4-9d32-dfd76196b9cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Progress Monitor enhancement to support the scheduled AutoML tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff83a2c-df0b-4511-a030-dd2be73db89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.utility import Settings\n",
    "Settings.set_log_level()\n",
    "from datetime import datetime\n",
    "\n",
    "from hana_ml.hana_scheduler import HANAScheduler\n",
    "hana_schedule = HANAScheduler(cc)\n",
    "\n",
    "job_name = \"my_job_{}\".format(str(uuid.uuid1())[:8])\n",
    "\n",
    "# Create scheduled job for the AutoML-fit task using \"creating_training_schedule\"\n",
    "hana_schedule.create_training_schedule(job_name=job_name,\n",
    "                                       obj=auto_c,\n",
    "                                       cron=\"* * * mon,tue,wed,thu,fri {} {} {}\".format(datetime.now().hour - 8, #UTC BJ\n",
    "                                                                                        datetime.now().minute,\n",
    "                                                                                        datetime.now().second),\n",
    "                                       output_table_names=['DM_BEST_PIPELINE_', 'DM_MODEL_', 'DM_INFO_'],\n",
    "                                       force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19a8ac-8865-4ff5-81e6-17a8d682e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf12d6-8050-48b7-a742-595c15b1e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hana_schedule.display_schedule_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f224b-1c26-44ed-b4c1-ad830dd2049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.visualizers.automl_progress import SimplePipelineProgressStatusMonitor\n",
    "\n",
    "progress_status_monitor = SimplePipelineProgressStatusMonitor(connection_context=cc)\n",
    "\n",
    "progress_status_monitor.start(progress_indicator_id=progress_id, \n",
    "                              highlight_metric='AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68131025-5618-4e21-a967-b47a45ed57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hana_schedule.delete_schedule(job_name)\n",
    "Settings.set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34fc19b-eafa-4c2b-b5f1-567c6a7c1749",
   "metadata": {},
   "source": [
    "## Time Series Analysis and Forecasting enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd146c0b-c4e4-4d7f-a4c7-f88b792e27a5",
   "metadata": {},
   "source": [
    "### Time series outlier detection with voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea5366-beba-4021-9036-6bdf6964cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ts data for illustrating this feature\n",
    "data = [[1,  '2008-03-09',  13],\n",
    "        [2,  '2008-03-10',  16],\n",
    "        [3,  '2008-03-11',  14],\n",
    "        [4,  '2008-03-12',  10],\n",
    "        [5,  '2008-03-13',  10],\n",
    "        [6,  '2008-03-14',  510],\n",
    "        [7,  '2008-03-15',  510],\n",
    "        [8,  '2008-03-16',  510],\n",
    "        [9,  '2008-03-17',  510],\n",
    "        [10, '2008-03-18',  516]]\n",
    "col_name = [\"ID\", \"timestamp\", \"y\"]\n",
    "df_s = pd.DataFrame(data=data, columns=col_name)\n",
    "df_s = create_dataframe_from_pandas(connection_context=cc, \n",
    "                                    pandas_df=df_s,\n",
    "                                    table_name='TEST_SINGLE_OUTLIER_DETECTION', \n",
    "                                    force=True, \n",
    "                                    replace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9495f-90db-4f88-bc8c-79abe7373f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using voting_config for defining which stats to be used with the outlier voting\n",
    "from hana_ml.algorithms.pal.tsa.outlier_detection import OutlierDetectionTS\n",
    "\n",
    "od = OutlierDetectionTS(window_size=5,\n",
    "                        detect_seasonality=False,                 \n",
    "                        outlier_method='z1',\n",
    "                        threshold=5,\n",
    "                        contamination=0.5,\n",
    "                        voting_outlier_method_criterion=0.5,\n",
    "                        dbscan_normalization=False,\n",
    "                        voting_config={\"z1\": {\"threshold\":100}, \"z2\": {\"threshold\":1}, \n",
    "                                       \"iqr\": {\"threshold\":2}, \"mad\":{\"threshold\":3},  \n",
    "                                       \"isolationforest\": {\"contamination\":0.4},\n",
    "                                       \"dbscan\": {'minpts':1,\n",
    "                                                  \"eps\":0.5,\n",
    "                                                  \"distiance_method\":\"euclidean\", \n",
    "                                                  \"dbscan_normalization\":True,\n",
    "                                                  \"dbscan_outlier_from_cluster\":False}},\n",
    "                       residual_usage=\"outlier_correction\")\n",
    "res=od.fit_predict(data=df_s, key='ID', endog='y')\n",
    "\n",
    "print(od.stats_.collect(), '\\n')\n",
    "print(res.head(2).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78735ce-6a7d-4d42-8bbd-b3abaa3e200f",
   "metadata": {},
   "source": [
    "### Segmented (massive-parallel) time series Online Bayesian Change Point Detection (Online BCPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7703bad0-93b9-48e1-bb1e-f8e37eef0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ts data for illustrating this feature\n",
    "data = [['100', 100, 1,  '2008-03-09',  13],\n",
    "        ['100', 100, 2,  '2008-03-10',  16],\n",
    "        ['100', 100, 3,  '2008-03-11',  14],\n",
    "        ['100', 100, 4,  '2008-03-12',  10],\n",
    "        ['100', 100, 5,  '2008-03-13',  10],\n",
    "        ['100', 100, 6,  '2008-03-14',  510],\n",
    "        ['100', 100, 7,  '2008-03-15',  510],\n",
    "        ['100', 100, 8,  '2008-03-16',  510],\n",
    "        ['100', 100, 9,  '2008-03-17',  510],\n",
    "        ['100', 100, 10, '2008-03-18',  516],        \n",
    "        ['200', 200, 1,  '2008-07-09',  0],\n",
    "        ['200', 200, 2,  '2008-07-10',  0],\n",
    "        ['200', 200, 3,  '2008-07-11',  0],\n",
    "        ['200', 200, 4,  '2008-07-12',  13],\n",
    "        ['200', 200, 5,  '2008-07-13',  10],\n",
    "        ['200', 200, 6,  '2008-07-14',  10],\n",
    "        ['200', 200, 7,  '2008-07-15',  12],\n",
    "        ['200', 200, 8,  '2008-07-16',  10],\n",
    "        ['200', 200, 9,  '2008-07-17',  18],\n",
    "        ['200', 200, 10, '2008-07-18',  0]]\n",
    "col_name = [\"GROUP_id_NAR\", \"GROUP_id_INT\", \"ID\", \"timestamp\", \"y\"]\n",
    "df_m = pd.DataFrame(data=data, columns=col_name)\n",
    "df_m = create_dataframe_from_pandas(connection_context=cc, \n",
    "                                    pandas_df=df_m,\n",
    "                                    table_name='DATA_MASSIVE_ONLINE_BCPD_NOTEBOOK', \n",
    "                                    force=True, \n",
    "                                    replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03145150-10bd-43a4-96fb-6b15ab9fcfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the massive-parameter for invoking segmented time series online BCPD\n",
    "from hana_ml.algorithms.pal.tsa.changepoint import OnlineBCPD\n",
    "\n",
    "obcpd = OnlineBCPD(massive=True,\n",
    "                   group_params= {'100': {'threshold':100, 'prune' :False, 'delay':100},\n",
    "                                  '200': {'threshold':200, 'prune' :True,  'delay':200}})\n",
    "init_model, cp = obcpd.fit_predict(data=df_m, group_key=\"GROUP_id_NAR\", key='timestamp', endog='y')\n",
    "print(init_model.head(30).collect())\n",
    "##print(cp.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9ec7e-4cb8-40b8-93d6-2aa71b655763",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time Series external feature importance evaluation using value permutation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bb740-db4f-4127-83ff-2fa219d1f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ts data for illustrating this feature\n",
    "data_s = [[ 0 , '2018-03-01 00:00:00', 1001.186965,  1001.381398, 0],\n",
    "          [ 1 , '2018-03-01 01:00:00',  999.743681,  1000.449621, 0],\n",
    "          [ 2 , '2018-03-01 02:00:00',  998.273447,  1000.202493, 0],\n",
    "          [ 3 , '2018-03-01 03:00:00',  998.163017,   999.517705, 0],\n",
    "          [ 4 , '2018-03-01 04:00:00', 1001.023297,  1000.149800, 0],\n",
    "          [ 5 , '2018-03-01 05:00:00', 1001.802838,   999.582847, 1],\n",
    "          [ 6 , '2018-03-01 06:00:00', 1000.902042,  1001.485573, 0],\n",
    "          [ 7 , '2018-03-01 07:00:00',  999.679829,  1000.480978, 0],\n",
    "          [ 8 , '2018-03-01 08:00:00', 1000.374643,   998.741293, 1],\n",
    "          [ 9 , '2018-03-01 09:00:00',  998.764213,   997.642889, 0],\n",
    "          [ 10, '2018-03-01 10:00:00',  997.452251,   997.075054, 0],\n",
    "          [ 11, '2018-03-01 11:00:00',  996.122439,   998.310629, 0],\n",
    "          [ 12, '2018-03-01 12:00:00',  994.911779,   998.415049, 0],\n",
    "          [ 13, '2018-03-01 13:00:00',  994.764867,   998.523278, 0],\n",
    "          [ 14, '2018-03-01 14:00:00',  995.957687,   998.204968, 0],\n",
    "          [ 15, '2018-03-01 15:00:00',  994.190517,   996.617601, 0],\n",
    "          [ 16, '2018-03-01 16:00:00',  994.111706,   996.972823, 0],\n",
    "          [ 17, '2018-03-01 17:00:00',  994.128363,   997.372093, 0],\n",
    "          [ 18, '2018-03-01 18:00:00',  993.700500,   995.882251, 1],\n",
    "          [ 19, '2018-03-01 19:00:00',  993.504805,   995.968155, 0],\n",
    "          [ 20, '2018-03-01 20:00:00',  993.394271,   996.612626, 2],\n",
    "          [ 21, '2018-03-01 21:00:00',  994.302608,   997.103210, 0],\n",
    "          [ 22, '2018-03-01 22:00:00',  993.106145,   997.017516, 0],\n",
    "          [ 23, '2018-03-01 23:00:00',  993.412343,   997.597426, 0],\n",
    "          [ 24, '2018-03-02 00:00:00',  993.304751,   996.252572, 0]]\n",
    "col_name = [\"ID_INT\", \"ID_TIMESTAMP\", \"endog\", \"exog\", \"cate\"]\n",
    "df_s = pd.DataFrame(data=data_s, columns=col_name)\n",
    "df_s = create_dataframe_from_pandas(connection_context=cc, \n",
    "                                          pandas_df=df_s,\n",
    "                                          table_name='DATA_ARIMA_TBL_NOTEBOOK', \n",
    "                                          force=True, \n",
    "                                          replace=True)\n",
    "data_p_s = [[ 1,  '2018-03-02 01:00:00',  998.37443, 998.364324, 0],\n",
    "            [ 2,  '2018-03-02 02:00:00',  1002.74643, 997.995616, 0],\n",
    "            [ 3,  '2018-03-02 03:00:00',  1001.31243, 996.582251, 1],\n",
    "            [ 4,  '2018-03-02 04:00:00',  1003.97401, 994.965102, 1],\n",
    "            [ 5,  '2018-03-02 05:00:00',  1000.37643, 995.522703, 0]]\n",
    "col_name = [\"ID_INT\", \"ID_TIMESTAMP\", \"endog\", \"exog\", \"cate\"]\n",
    "data_p_s = pd.DataFrame(data=data_p_s, columns=col_name)\n",
    "\n",
    "data_p_s = create_dataframe_from_pandas(connection_context=cc, \n",
    "                                            pandas_df=data_p_s,\n",
    "                                            table_name='DATA_ARIMA_PREDICT_TBL_NOTEBOOK', \n",
    "                                            force=True, \n",
    "                                            replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a23f30-aa0b-4a41-87a6-71fdbc5e2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.tsa.arima import ARIMA\n",
    "from hana_ml.algorithms.pal.tsa.permutation_importance import permutation_importance\n",
    "# ARIMA ID=INT\n",
    "ar = ARIMA()\n",
    "ar.fit(df_s, key='ID_INT', endog='endog', exog=['exog', 'cate'])\n",
    "print(ar.model_.head(2).collect())\n",
    "#res = ar.predict(df_s_p.deselect(['ID_TIMESTAMP', 'endog']), key='ID_INT')\n",
    "#print(res.collect())\n",
    "pires = permutation_importance(data=data_p_s, model=ar.model_, key='ID_INT', endog='endog', exog=['exog', 'cate'])\n",
    "print(pires.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d910af-7131-4117-b1ea-aa258525d873",
   "metadata": {},
   "source": [
    "## Recommendation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67626108-ac44-4218-818e-0bf8d15993fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multilayer Perceptron (MLP) Neural Network Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3dd8c-6388-4159-b880-2cca4fbf2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_full = DataSets.load_boston_housing_data(cc)\n",
    "bst_train, bst_test = bst_full[1], bst_full[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156e7f0-35b8-4696-b468-40ca367552d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.recommender import MLPRecommender\n",
    "\n",
    "mlpr_reg = MLPRecommender( learning_rate=0.1, num_epochs=1000, random_state=2023) \n",
    "cols = bst_train.columns\n",
    "cols.remove('ID')\n",
    "cols.remove('MEDV')\n",
    "\n",
    "mlpr_reg.fit(data=bst_train, key='ID', label='MEDV',\n",
    "             selected_feature_set1=cols,\n",
    "             selected_feature_set2=cols)\n",
    "\n",
    "mlpr_reg.runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4d090-97e8-4f53-8087-102b4193b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mlpr_reg.predict(bst_test, key='ID')\n",
    "res.head(10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42372d0-e7e3-4ae3-8d73-f3a1077686a5",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa59010-4f9d-4ab1-8f8e-2ae590da50fa",
   "metadata": {},
   "source": [
    "### Bubble Plot & Parallel Co-ordinate Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0d147-d6f2-473c-92dc-dda7c73228cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from hana_ml.dataframe import create_dataframe_from_pandas\n",
    "\n",
    "num_point=100\n",
    "x = np.random.rand(num_point)\n",
    "y = np.random.rand(num_point)\n",
    "w = np.random.rand(num_point)\n",
    "z = np.random.rand(num_point)*1000\n",
    "cate = [random.randrange(1, 3, 1) for i in range(num_point)]\n",
    "label = [random.randrange(1, 5, 1) for i in range(num_point)]\n",
    "color = np.random.rand(num_point)\n",
    "\n",
    "content = {'X':x, 'Y':y, 'S':z, 'W':w, 'cate':cate, 'label':label}\n",
    "df_pd=pd.DataFrame(content)\n",
    "print(df_pd.dtypes)\n",
    "df = create_dataframe_from_pandas(cc, \n",
    "                                  pandas_df=df_pd,\n",
    "                                  table_name='DATA', \n",
    "                                  force=True, \n",
    "                                  replace=True)\n",
    "df_new = df.cast({\"cate\":\"NVARCHAR(20)\"})\n",
    "full_set, training_set, validation_set, test_set = DataSets.load_iris_data(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627a558-5004-42b7-b4de-446c565fe65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.visualizers.eda import parallel_coordinates, bubble_plot\n",
    "\n",
    "fig = bubble_plot(df_new, x='X', y='Y', size='S', title=\"bubble plot\", width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ce9c3-1009-4e30-9032-711327f3ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = parallel_coordinates(data=full_set.deselect(\"ID\"), label='SPECIES', \n",
    "                          cols=['SEPALLENGTHCM', 'SEPALWIDTHCM', 'PETALLENGTHCM', 'PETALWIDTHCM'],\n",
    "                          width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee59ff-0f2c-4a4a-8d0b-722ba0729fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
