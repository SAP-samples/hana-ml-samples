{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# hana-ml Tutorial - Auto ML\n",
    "\n",
    "**Author: TI HDA DB HANA Core CN**\n",
    "\n",
    "In this tutorial, we will show you how to use AutoML(AutomaticClassification/AutomaticRegression) in hana-ml to train classification/regression model with public datasets. \n",
    "\n",
    "## Import the Necessary Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from hana_ml import dataframe\n",
    "from hana_ml.dataframe import ConnectionContext\n",
    "from hana_ml.algorithms.pal.utility import DataSets, Settings\n",
    "from hana_ml.algorithms.pal.partition import train_test_val_split\n",
    "from hana_ml.algorithms.pal.auto_ml import AutomaticClassification, AutomaticRegression\n",
    "from hana_ml.visualizers.automl_progress import PipelineProgressStatusMonitor\n",
    "from hana_ml.visualizers.automl_report import BestPipelineReport\n",
    "from hana_ml.visualizers.unified_report import UnifiedReport\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a connection to a SAP HANA instance\n",
    "\n",
    "First, you need to create a connetion to a SAP HANA instance. In the following cell, we use a config file, config/e2edata.ini to control the connection parameters. \n",
    "\n",
    "In your case, please update the following url, port, user, pwd with your HANA instance information for setting up the connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Please replace url, port, user, pwd with your HANA instance information\n",
    "connection_context = ConnectionContext(url, port, user, pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AutomaticClassification\n",
    "\n",
    "Diabetes dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
    "\n",
    "1. **PREGNANCIES**: Number of times pregnant\n",
    "2. **GLUCOSE**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. **BLOODPRESSURE**: Diastolic blood pressure (mm Hg)\n",
    "4. **SKINTHICKNESS**: Triceps skin fold thickness (mm)\n",
    "5. **INSULIN**: 2-Hour serum insulin (mu U/ml)\n",
    "6. **BMI**: Body mass index (weight in kg/(height in m)^2)\n",
    "7. **PEDIGREE**: Diabetes pedigree function\n",
    "8. **AGE**: Age (years)\n",
    "9. **CLASS**: Class variable (0 or 1),  **target varaible**.\n",
    "\n",
    "In hana-ml, we provide a class called DataSets which contains several public datasets. You could use load_diabetes_data to load the diabetes dataset.\n",
    "\n",
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "diabetes_dataset, _, _, _ = DataSets.load_diabetes_data(connection_context)\n",
    "\n",
    "# number of rows and number of columns\n",
    "print(\"Shape of diabetes datset: {}\".format(diabetes_dataset.shape))\n",
    "\n",
    "# columns\n",
    "print(diabetes_dataset.columns)\n",
    "\n",
    "# cast the label to be NVARCHAR\n",
    "diabetes_dataset = diabetes_dataset.cast('CLASS', 'VARCHAR')\n",
    "\n",
    "# types of each column\n",
    "print(diabetes_dataset.dtypes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Dataset Report\n",
    "UnifiedReport(diabetes_dataset).build().display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into a training and a test dataset\n",
    "df_diabetes_train, df_diabetes_test, _ = train_test_val_split(data=diabetes_dataset, \n",
    "                                                              random_seed=2,\n",
    "                                                              training_percentage=0.8,\n",
    "                                                              testing_percentage=0.2,\n",
    "                                                              validation_percentage=0,\n",
    "                                                              id_column='ID',\n",
    "                                                              partition_method='stratified',\n",
    "                                                              stratified_column='CLASS')\n",
    "print(\"Number of training samples: {}\".format(df_diabetes_train.count()))\n",
    "print(\"Number of test samples: {}\".format(df_diabetes_test.count()))\n",
    "\n",
    "# delete label column in the test dataset\n",
    "df_diabetes_test = df_diabetes_test.deselect('CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Look at the first three row of data\n",
    "print(df_diabetes_train.head(3).collect())\n",
    "print(df_diabetes_test.head(3).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke AutomaticClassification\n",
    "\n",
    "When you invoke AutomaticClassification, please use enable_workload_class() to manage workload in your SAP HANA instance. More detail could be see in the SAP help portal:\n",
    "\n",
    "https://help.sap.com/viewer/afa922439b204e9caf22c78b6b69e4f2/2.10.0.0/en-US/4499964b5ace432a80c572cc434240ab.html\n",
    "\n",
    "In this example, we have configured a Workload Class in the SAP HANA database called \"PAL_AUTOML_WORKLOAD\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutomaticClassification init \n",
    "progress_id = \"automl_{}\".format(uuid.uuid1())\n",
    "auto_c = AutomaticClassification(generations=2, \n",
    "                                 population_size=5,\n",
    "                                 offspring_size=5, \n",
    "                                 progress_indicator_id=progress_id,\n",
    "                                 early_stop=1,\n",
    "                                 max_eval_time_mins=1,\n",
    "                                 random_seed=1234,\n",
    "                                 scorings={\"F1_SCORE_1\": 1.0},\n",
    "                                 elite_number=3)\n",
    "\n",
    "# enable_workload_class\n",
    "auto_c.enable_workload_class(workload_class_name=\"PAL_AUTOML_WORKLOAD\")\n",
    "\n",
    "# invoke a PipelineProgressStatusMonitor\n",
    "progress_status_monitor = PipelineProgressStatusMonitor(connection_context=connection_context, \n",
    "                                                        automatic_obj=auto_c)\n",
    "\n",
    "progress_status_monitor.start()\n",
    "\n",
    "# training\n",
    "try:\n",
    "    auto_c.fit(data=df_diabetes_train, key=\"ID\")\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best pipeline plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestPipelineReport(auto_c).generate_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = auto_c.predict(df_diabetes_test, key=\"ID\")\n",
    "print(res.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the existing pipeline to fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best pipeline after training\n",
    "auto_c.best_pipeline_.collect().iat[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = auto_c.best_pipeline_.collect().iat[0, 1]\n",
    "\n",
    "auto_c.fit(df_diabetes_train, pipeline=pipeline, key=\"ID\")\n",
    "\n",
    "res = auto_c.predict(df_diabetes_test, key=\"ID\")\n",
    "print(res.collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutomaticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "bike_dataset = DataSets.load_bike_data(connection_context)\n",
    "\n",
    "# number of rows and number of columns\n",
    "print(\"Shape of datset: {}\".format(bike_dataset.shape))\n",
    "\n",
    "# columns\n",
    "print(bike_dataset.columns)\n",
    "\n",
    "# types of each column\n",
    "print(bike_dataset.dtypes())\n",
    "\n",
    "# print the first 3 rows of dataset\n",
    "print(bike_dataset.head(3).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Dataset Report\n",
    "UnifiedReport(bike_dataset).build().display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a ID column for AutomaticRegression, the last column is the label\n",
    "bike_dataset = bike_dataset.add_id('ID', ref_col='days_since_2011')\n",
    "\n",
    "# Split the dataset into training and test dataset\n",
    "cols = bike_dataset.columns\n",
    "cols.remove('cnt')\n",
    "bike_data = bike_dataset[cols + ['cnt']]\n",
    "\n",
    "bike_train = bike_data.filter('ID <= 600')\n",
    "bike_test = bike_data.filter('ID > 600')\n",
    "print(bike_train.head(3).collect())\n",
    "print(bike_test.head(3).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke AutomaticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutomaticRegression init \n",
    "progress_id = \"automl_reg_{}\".format(uuid.uuid1())\n",
    "auto_r = AutomaticRegression(generations=2,\n",
    "                             population_size=5,\n",
    "                             offspring_size=5,                             \n",
    "                             progress_indicator_id=progress_id)\n",
    "\n",
    "# enable_workload_class\n",
    "auto_r.enable_workload_class(workload_class_name=\"PAL_AUTOML_WORKLOAD\")\n",
    "\n",
    "# invoke a PipelineProgressStatusMonitor\n",
    "progress_status_monitor = PipelineProgressStatusMonitor(connection_context=connection_context, \n",
    "                                                        automatic_obj=auto_r)\n",
    "\n",
    "progress_status_monitor.start()\n",
    "try:\n",
    "    auto_r.fit(bike_train, key=\"ID\")\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best pipeline plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestPipelineReport(auto_r).generate_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = auto_r.predict(bike_test.deselect('cnt'), key=\"ID\")\n",
    "print(res.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the existing pipeline to fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auto_r.best_pipeline_.collect().iat[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = auto_r.best_pipeline_.collect().iat[0, 1]\n",
    "\n",
    "auto_r.fit(bike_train, pipeline=pipeline, key=\"ID\")\n",
    "\n",
    "res = auto_r.predict(bike_test.deselect('cnt'), key=\"ID\")\n",
    "print(res.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_context.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
