{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1dd0ca8e-05d4-488f-9b12-8ae373186117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install hana_ml mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "13910b57-e0c3-4d57-bc99-99b8de3e2dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import hana_ml\n",
    "from hana_ml import dataframe\n",
    "import mlflow\n",
    "print(hana_ml.__version__)\n",
    "print(mlflow.__version__    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ec2829f0-9512-4483-bea4-b4e763dfcb34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.utility import DataSets, Settings\n",
    "import os\n",
    "scope = \"<scope>\" #as defined in create_secrets\n",
    "os.environ[\"hana_url\"] = dbutils.secrets.get(scope=scope, key=\"hana_url\")\n",
    "os.environ[\"hana_port\"] = dbutils.secrets.get(scope=scope, key=\"hana_port\")\n",
    "os.environ[\"hana_user\"] = dbutils.secrets.get(scope=scope, key=\"hana_user\")\n",
    "os.environ[\"hana_password\"] = dbutils.secrets.get(scope=scope, key=\"hana_password\")\n",
    "\n",
    "connection_context = dataframe.ConnectionContext(os.environ[\"hana_url\"] ,os.environ[\"hana_port\"] ,os.environ[\"hana_user\"] , os.environ[\"hana_password\"])\n",
    "connection_context.connection.isconnected()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1c5db6a-f6ed-4d90-9283-e8ed74fa50a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define the model input and output signature\n",
    "Here the interface is the user provides \n",
    "- the name of the HANA Cloud inference table (this could be the same or another HANA Cloud instance where the training was done)\n",
    "- the output is the prediction for each row in the inference table identified by \"ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "851428e6-1271-4ef1-ab03-1e6aa6b5c7fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import ModelSignature, infer_signature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "signature = ModelSignature(inputs = Schema([ColSpec(\"string\", \"INFERENCE_TABLE_NAME\")]))\n",
    "\n",
    "signature.outputs = Schema([ColSpec(\"integer\", \"ID\"), ColSpec(\"double\", \"SCORES\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18142062-e65c-4a8c-864a-a33569933589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create the custom pyfunc model for hana-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8ca970e-414e-43cb-a34b-6bd91f082391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save as script: hana_ml_pyfunc_model.py\n",
    "# %%writefile \"./hana_ml_pyfunc_model.py\"\n",
    "import mlflow\n",
    "from mlflow import pyfunc\n",
    "from mlflow.models import set_model\n",
    "import hana_ml\n",
    "from hana_ml import dataframe\n",
    "from hana_ml.model_storage import ModelStorage\n",
    "import os\n",
    "\n",
    "class CustomException(Exception):\n",
    "    \"\"\"Exception raised to get messages\n",
    "    Attributes:\n",
    "        message -- explanation of the error\n",
    "    \"\"\"\n",
    "    def __init__(self, message=\"HANA ML Pyfunc Custom Exception\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "\n",
    "class hana_ml_pyfunc_model(pyfunc.PythonModel):\n",
    "\n",
    "    def connectToHANA(self, context):\n",
    "        try:\n",
    "            url =  os.getenv('hana_url') \n",
    "            port = os.getenv('hana_port')\n",
    "            user = os.getenv('hana_user')\n",
    "            passwd = os.getenv('hana_password')\n",
    "            connection_context = dataframe.ConnectionContext(url, port, user, passwd)\n",
    "            return connection_context\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred: {e}\")\n",
    "            raise e\n",
    "            return \"Exception:{e}\", e\n",
    "    @mlflow.trace\n",
    "    def load_context(self, context):\n",
    "        try: \n",
    "            with mlflow.start_span(\"load_context\"):\n",
    "                self.model = context.artifacts[\"model\"]\n",
    "                self.connection_context = self.connectToHANA(context)\n",
    "                print(\"HANA_ML_MODEL loaded in load_context\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred: {e}\")\n",
    "            raise Exception(f\"Loading the context failed due to {e}\")\n",
    "    @mlflow.trace\n",
    "    def predict(self, context, model_input):\n",
    "        table_name = None\n",
    "        try: \n",
    "            if self.connection_context.connection.isconnected() == False:\n",
    "                with mlflow.start_span(\"connect_to_HANA\"):\n",
    "                    self.connection_context = self.connectToHANA(context)\n",
    "                    if self.connection_context.connection.isconnected():\n",
    "                        print(\"HANA Connection Successful\")\n",
    "                    else:\n",
    "                        raise Exception(\"HANA Connection Failed\")\n",
    "       \n",
    "            with mlflow.start_span(\"load_model\"):\n",
    "                hana_model = ModelStorage.load_mlflow_model(connection_context=self.connection_context, model_uri=self.model,use_temporary_table=False, force=True)\n",
    "           \n",
    "                print(\"HANA_ML_MODEL loaded in predict\")\n",
    "                print(\"model_input\", model_input)\n",
    "                table_name = str(model_input[\"INFERENCE_TABLE_NAME\"][0]) \n",
    "                print(\"Table Name:\", table_name)\n",
    "            with mlflow.start_span(\"hana_ml_predict\"):\n",
    "                df = self.connection_context.table(table_name)\n",
    "                if df.count() > 0:\n",
    "                  \n",
    "                    print(f\"Running HANA ML inference on {table_name} with {df.count()} records\")\n",
    "                    prediction = hana_model.predict(df, key = \"ID\").collect()\n",
    "                    print(\"Prediction completed\")\n",
    "                    return  prediction\n",
    "                else:\n",
    "                    raise Exception(f\"HANA Inference Table {table_name} is empty\")\n",
    "        \n",
    "            \n",
    "        except Exception as e:\n",
    "        \n",
    "            print(f\"Exception occurred: {e}\")\n",
    "            raise f\"Exception:{e}\"\n",
    "        \n",
    "set_model(hana_ml_pyfunc_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3892642-03e5-46a0-a544-966a7ab64f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log the custom pyfunc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63dab23a-7ab1-4816-a436-cf141b8c4f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "runid='<selected runid which has the chosen model>' #this is the run_id from training run in 1_hana_mlflow_ar_bike_test_train\n",
    "model_uri='runs:/{}/model'.format(runid)\n",
    "\n",
    "experiment_name = '<experiment_name>' \n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "model_file = \"hana_ml_pyfunc_model.py\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"model\",\n",
    "            python_model=model_file,\n",
    "            artifacts={\"model\": model_uri},\n",
    "            pip_requirements=[\"hana-ml\",\"ipython\"],\n",
    "            signature = signature,\n",
    "            input_example={\"INFERENCE_TABLE_NAME\" : \"INFERENCE_BIKE_DATA_TBL\"},\n",
    "           \n",
    "    )\n",
    "# Register the model\n",
    "model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "registered_model_name = \"<registered_model_name>\"\n",
    "mlflow.register_model(model_uri=model_uri, name=registered_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed38e143-58f1-4e2c-977d-bfbc56e9b8aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20336423-e2d9-42a0-a13c-40587310c72b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_id = \"<run_id of model logged above>\" #run.info.run_id\n",
    "logged_model = f'runs:/{run_id}/model'\n",
    "dataset = {\"inputs\": {\"INFERENCE_TABLE_NAME\" : \"INFERENCE_BIKE_DATA_TBL\"}}\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "loaded_model.predict(dataset[\"inputs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca30f01b-f9c1-47d5-91a5-e066b45b2e6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test the model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d96a3342-b410-44ba-8583-14eced437456",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f02d96-a5e9-4a00-a164-11ce0e17ddc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "run_id = \"<run_id of model logged above>\" #run.info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "dataset = {\"inputs\": {\"INFERENCE_TABLE_NAME\" : \"INFERENCE_BIKE_DATA_TBL\"}}\n",
    "input_data = dataset\n",
    "\n",
    "mlflow.models.predict(\n",
    "    model_uri=model_uri,\n",
    "    input_data=dataset[\"inputs\"],\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5aa9df8-812a-4043-93fb-15d60fab577f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Now we can deploy the registered model following steps here [Model Serving](https://docs.databricks.com/aws/en/machine-learning/model-serving/store-env-variable-model-serving?language=Serving%C2%A0UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a63121c6-7945-43ca-b3d1-7b6d0414d895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "client = get_deploy_client(\"databricks\")\n",
    "endpoint = client.create_endpoint(\n",
    "    name=\"hana-mlflow-serving\",\n",
    "    config={\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"name\": \"hana-ml-ar\",\n",
    "                \"entity_name\": registered_model_name,\n",
    "                \"entity_version\": \"1\",\n",
    "                \"workload_size\": \"Small\",\n",
    "                \"scale_to_zero_enabled\": True,\n",
    "                \"environment_vars\": {\n",
    "                    \"ENABLE_MLFLOW_TRACING\": \"true\",\n",
    "                    \"hana_url\": os.environ[\"hana_url\"],\n",
    "                    \"hana_port\": os.environ[\"hana_port\"],\n",
    "                    \"hana_user\": os.environ[\"hana_user\"],\n",
    "                    \"hana_password\": os.environ[\"hana_password\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_hana_ml_prepare_serving",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
